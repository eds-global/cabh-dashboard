{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d8642dc-21d9-4329-ab3e-98855982e044",
   "metadata": {},
   "source": [
    "## Creating Excel files for missing and zero values data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7cf28e-b5ce-4690-80db-0bdf98279e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Database credentials\n",
    "host = \"139.59.34.149\"\n",
    "user = \"neemdb\"\n",
    "password = \"(#&pxJ&p7JvhA7<B\"\n",
    "database = \"cabh_iaq_db\"\n",
    "\n",
    "# List of all device IDs you want to process\n",
    "device_ids = [1202240026,1202240025,1203240081,1202240011,1202240027,1203240076,1203240078,1203240075,1201240077,\n",
    "    1201240072,1203240079,1201240079 ,1201240085 ,1203240083 ,1203240073 ,1203240074,1201240076,1212230160 ,\n",
    "    1202240009 ,1202240008,1201240073,1203240080,1201240074,1203240077,1203240082,1202240029,1202240028,1202240010,1202240012]\n",
    "\n",
    "# Directory to save Excel files\n",
    "save_dir = r\"C:\\Users\\abhis\\Data_Validation\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Connect to the database\n",
    "conn = None\n",
    "try:\n",
    "    conn = mysql.connector.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "    print(\"Database connection successful.\")\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # SQL query\n",
    "    query = \"\"\"\n",
    "    SELECT id, deviceID, datetime, pm25, pm10, aqi, co2, voc, temp, humidity, battery, viral_index\n",
    "    FROM reading_db\n",
    "    WHERE deviceID = %s;\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop over each ID\n",
    "    for id_to_fetch in device_ids:\n",
    "        print(f\"\\nProcessing Device ID: {id_to_fetch}\")\n",
    "        cursor.execute(query, (id_to_fetch,))\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows, columns=[\"id\", \"deviceID\", \"datetime\", \"pm25\", \"pm10\", \"aqi\", \"co2\", \"voc\", \"temp\", \"humidity\", \"battery\", \"viral_index\"])\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "            df = df.dropna(subset=['datetime'])\n",
    "            df['date'] = df['datetime'].dt.date\n",
    "\n",
    "            all_dates = pd.date_range(df['date'].min(), df['date'].max(), freq='D').date\n",
    "            existing_dates = df['date'].unique()\n",
    "            missing_dates = [date for date in all_dates if date not in existing_dates]\n",
    "\n",
    "            zero_data_dates = []\n",
    "            for date in df['date'].unique():\n",
    "                day_data = df[df['date'] == date]\n",
    "                if (day_data[['pm25', 'pm10', 'aqi', 'co2', 'voc', 'temp', 'humidity', 'battery', 'viral_index']] == 0).all().all():\n",
    "                    zero_data_dates.append(date)\n",
    "\n",
    "            df1 = pd.DataFrame(missing_dates, columns=['Missing Dates'])\n",
    "            df2 = pd.DataFrame(zero_data_dates, columns=['Zero Values'])\n",
    "\n",
    "            df_con = pd.concat([df1, df2], axis=1)\n",
    "            file_path = os.path.join(save_dir, f\"{id_to_fetch}.xlsx\")\n",
    "            df_con.to_excel(file_path, index=False)\n",
    "            print(f\"Data for Device ID {id_to_fetch} saved to {file_path}\")\n",
    "        else:\n",
    "            print(f\"No data found for Device ID: {id_to_fetch}\")\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Error while connecting to the database or fetching data:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"\\nConnection closed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1496b03c-bdc1-48cc-8d01-bf8a4f7df7aa",
   "metadata": {},
   "source": [
    "### Including Percentage of Presence of data for a particular day in Excel files (End datetime is define explicitly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7059fc45-91a9-40e1-b1f9-1a3c10ccb73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful.\n",
      "\n",
      "Processing Device ID: 1201240085\n",
      "Data for Device ID 1201240085 saved to C:\\Users\\abhis\\Data_Validation_05-08\\1201240085.xlsx\n",
      "\n",
      "Processing Device ID: 1203240083\n",
      "Data for Device ID 1203240083 saved to C:\\Users\\abhis\\Data_Validation_05-08\\1203240083.xlsx\n",
      "\n",
      "Processing Device ID: 1203240073\n",
      "Data for Device ID 1203240073 saved to C:\\Users\\abhis\\Data_Validation_05-08\\1203240073.xlsx\n",
      "\n",
      "Processing Device ID: 1203240074\n",
      "Data for Device ID 1203240074 saved to C:\\Users\\abhis\\Data_Validation_05-08\\1203240074.xlsx\n",
      "\n",
      "Processing Device ID: 1201240076\n",
      "Data for Device ID 1201240076 saved to C:\\Users\\abhis\\Data_Validation_05-08\\1201240076.xlsx\n",
      "\n",
      "Processing Device ID: 1212230160\n",
      "Data for Device ID 1212230160 saved to C:\\Users\\abhis\\Data_Validation_05-08\\1212230160.xlsx\n",
      "\n",
      "Processing Device ID: 1202240009\n",
      "Data for Device ID 1202240009 saved to C:\\Users\\abhis\\Data_Validation_05-08\\1202240009.xlsx\n",
      "\n",
      "Processing Device ID: 1202240008\n",
      "Data for Device ID 1202240008 saved to C:\\Users\\abhis\\Data_Validation_05-08\\1202240008.xlsx\n",
      "\n",
      "Processing Device ID: 1201240073\n",
      "Data for Device ID 1201240073 saved to C:\\Users\\abhis\\Data_Validation_05-08\\1201240073.xlsx\n",
      "\n",
      "Processing Device ID: 1203240080\n",
      "Data for Device ID 1203240080 saved to C:\\Users\\abhis\\Data_Validation_05-08\\1203240080.xlsx\n",
      "\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Database credentials\n",
    "host = \"139.59.34.149\"\n",
    "user = \"neemdb\"\n",
    "password = \"(#&pxJ&p7JvhA7<B\"\n",
    "database = \"cabh_iaq_db\"\n",
    "\n",
    "# List of all device IDs you want to process\n",
    "device_ids = [  \n",
    "              1201240085, 1203240083, 1203240073, 1203240074, 1201240076, 1212230160,\n",
    "              1202240009, 1202240008, \n",
    "              1201240073, 1203240080, ]\n",
    "\n",
    "# Directory to save Excel files\n",
    "save_dir = r\"C:\\Users\\abhis\\Data_Validation_05-08\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Connect to the database\n",
    "conn = None\n",
    "try:\n",
    "    conn = mysql.connector.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "    print(\"Database connection successful.\")\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # SQL query\n",
    "    query = \"\"\"\n",
    "    SELECT id, deviceID, datetime, pm25, pm10, aqi, co2, voc, temp, humidity, battery, viral_index\n",
    "    FROM reading_db\n",
    "    WHERE deviceID = %s;\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop over each ID\n",
    "    for id_to_fetch in device_ids:\n",
    "        print(f\"\\nProcessing Device ID: {id_to_fetch}\")\n",
    "        cursor.execute(query, (id_to_fetch,))\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows, columns=[\"id\", \"deviceID\", \"datetime\", \"pm25\", \"pm10\", \"aqi\", \"co2\", \"voc\", \"temp\", \"humidity\", \"battery\", \"viral_index\"])\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "            df = df.dropna(subset=['datetime'])\n",
    "            df['date'] = df['datetime'].dt.date\n",
    "            # df.to_csv('testing_data_validation.csv')\n",
    "\n",
    "            all_dates = pd.date_range(df['date'].min(), df['date'].max(), freq='D').date\n",
    "            existing_dates = df['date'].unique()\n",
    "            missing_dates = [date for date in all_dates if date not in existing_dates]\n",
    "\n",
    "            # Finding Zero value data.\n",
    "            zero_data_dates = []\n",
    "            for date in df['date'].unique():\n",
    "                day_data = df[df['date'] == date]\n",
    "                if (day_data[['pm25', 'pm10', 'aqi', 'co2', 'voc', 'temp', 'humidity', 'battery', 'viral_index']] == 0).all().all():\n",
    "                    zero_data_dates.append(date)\n",
    "\n",
    "            # Calculate data presence percentage for each day\n",
    "            data_presence = []\n",
    "            for date in df['date'].unique():\n",
    "                day_data = df[df['date'] == date]\n",
    "                presence_percentage = (len(day_data) / 1440) * 100  # 1440 minutes in a day\n",
    "                data_presence.append({'Date': date, 'Data Presence (%)': presence_percentage})\n",
    "\n",
    "            start_datetime = df['datetime'].min()\n",
    "            forced_end_datetime = pd.to_datetime(\"2025-03-31 23:59\")\n",
    "            \n",
    "            # Adjust end_datetime if data is shorter than expected period\n",
    "            end_datetime = forced_end_datetime\n",
    "            \n",
    "            total_minutes = int((end_datetime - start_datetime).total_seconds() / 60) + 1\n",
    "            expected_records = total_minutes\n",
    "            actual_records = len(df)\n",
    "            overall_data_quality = (actual_records / expected_records) * 100\n",
    "\n",
    "\n",
    "            \n",
    "            df1 = pd.DataFrame(missing_dates, columns=['Missing Dates'])\n",
    "            df2 = pd.DataFrame(zero_data_dates, columns=['Zero Values'])\n",
    "            df3 = pd.DataFrame(data_presence)\n",
    "            quality_df = pd.DataFrame({\n",
    "                'Metric': ['Device ID', 'Start Datetime', 'End Datetime', 'Expected Records', 'Actual Records', 'Data Quality (%)'],\n",
    "                'Value': [id_to_fetch, start_datetime, end_datetime, expected_records, actual_records, overall_data_quality]\n",
    "            })\n",
    "            \n",
    "\n",
    "            df_con = pd.concat([df1, df2, df3,quality_df], axis=1)\n",
    "            file_path = os.path.join(save_dir, f\"{id_to_fetch}.xlsx\")\n",
    "            df_con.to_excel(file_path, index=False)\n",
    "            print(f\"Data for Device ID {id_to_fetch} saved to {file_path}\")\n",
    "        else:\n",
    "            print(f\"No data found for Device ID: {id_to_fetch}\")\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Error while connecting to the database or fetching data:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"\\nConnection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3c7fa1c-0873-4bbe-8bd3-69baac941fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful.\n",
      "\n",
      "Processing Device ID: 1202240026\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1202240026 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1202240026.xlsx\n",
      "\n",
      "Processing Device ID: 1202240025\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1202240025 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1202240025.xlsx\n",
      "\n",
      "Processing Device ID: 1203240081\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240081 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240081.xlsx\n",
      "\n",
      "Processing Device ID: 1202240011\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1202240011 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1202240011.xlsx\n",
      "\n",
      "Processing Device ID: 1202240027\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1202240027 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1202240027.xlsx\n",
      "\n",
      "Processing Device ID: 1203240076\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240076 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240076.xlsx\n",
      "\n",
      "Processing Device ID: 1203240078\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240078 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240078.xlsx\n",
      "\n",
      "Processing Device ID: 1203240075\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240075 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240075.xlsx\n",
      "\n",
      "Processing Device ID: 1201240077\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1201240077 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1201240077.xlsx\n",
      "\n",
      "Processing Device ID: 1201240072\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:54\n",
      "Data for Device ID 1201240072 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1201240072.xlsx\n",
      "\n",
      "Processing Device ID: 1203240079\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240079 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240079.xlsx\n",
      "\n",
      "Processing Device ID: 1201240079\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1201240079 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1201240079.xlsx\n",
      "\n",
      "Processing Device ID: 1201240085\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1201240085 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1201240085.xlsx\n",
      "\n",
      "Processing Device ID: 1203240083\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240083 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240083.xlsx\n",
      "\n",
      "Processing Device ID: 1203240073\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240073 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240073.xlsx\n",
      "\n",
      "Processing Device ID: 1203240074\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240074 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240074.xlsx\n",
      "\n",
      "Processing Device ID: 1201240076\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1201240076 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1201240076.xlsx\n",
      "\n",
      "Processing Device ID: 1212230160\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1212230160 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1212230160.xlsx\n",
      "\n",
      "Processing Device ID: 1202240009\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1202240009 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1202240009.xlsx\n",
      "\n",
      "Processing Device ID: 1202240008\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1202240008 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1202240008.xlsx\n",
      "\n",
      "Processing Device ID: 1201240073\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1201240073 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1201240073.xlsx\n",
      "\n",
      "Processing Device ID: 1203240080\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240080 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240080.xlsx\n",
      "\n",
      "Processing Device ID: 1201240074\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:14\n",
      "Data for Device ID 1201240074 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1201240074.xlsx\n",
      "\n",
      "Processing Device ID: 1203240077\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240077 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240077.xlsx\n",
      "\n",
      "Processing Device ID: 1203240082\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1203240082 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1203240082.xlsx\n",
      "\n",
      "Processing Device ID: 1202240029\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1202240029 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1202240029.xlsx\n",
      "\n",
      "Processing Device ID: 1202240028\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1202240028 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1202240028.xlsx\n",
      "\n",
      "Processing Device ID: 1202240010\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1202240010 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1202240010.xlsx\n",
      "\n",
      "Processing Device ID: 1202240012\n",
      "Latest datetime in filtered data: 2025-03-31 23:59:02\n",
      "Data for Device ID 1202240012 saved to C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\\1202240012.xlsx\n",
      "\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Database credentials\n",
    "host = \"139.59.34.149\"\n",
    "user = \"neemdb\"\n",
    "password = \"(#&pxJ&p7JvhA7<B\"\n",
    "database = \"cabh_iaq_db\"\n",
    "\n",
    "# Device IDs to process\n",
    "device_ids = [  \n",
    "    1202240026, 1202240025, 1203240081, 1202240011, 1202240027, 1203240076,\n",
    "    1203240078, 1203240075, 1201240077, 1201240072, 1203240079, 1201240079,\n",
    "    1201240085, 1203240083, 1203240073, 1203240074, 1201240076, 1212230160,\n",
    "    1202240009, 1202240008, 1201240073, 1203240080, 1201240074, 1203240077,\n",
    "    1203240082, 1202240029, 1202240028, 1202240010, 1202240012\n",
    "]\n",
    "\n",
    "# Output directory\n",
    "save_dir = r\"C:\\Users\\abhis\\Data_Validation_tillMarch_2024_06-08\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Forced end datetime\n",
    "FORCED_END_DATETIME = pd.to_datetime(\"2025-03-31 23:59:59\")\n",
    "\n",
    "# Connect to the database\n",
    "conn = None\n",
    "try:\n",
    "    conn = mysql.connector.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "    print(\"Database connection successful.\")\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # SQL query\n",
    "    query = \"\"\"\n",
    "    SELECT id, deviceID, datetime, pm25, pm10, aqi, co2, voc, temp, humidity, battery, viral_index\n",
    "    FROM reading_db\n",
    "    WHERE deviceID = %s;\n",
    "    \"\"\"\n",
    "\n",
    "    for id_to_fetch in device_ids:\n",
    "        print(f\"\\nProcessing Device ID: {id_to_fetch}\")\n",
    "        cursor.execute(query, (id_to_fetch,))\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows, columns=[\"id\", \"deviceID\", \"datetime\", \"pm25\", \"pm10\", \"aqi\", \"co2\", \"voc\", \"temp\", \"humidity\", \"battery\", \"viral_index\"])\n",
    "            \n",
    "            # Parse datetime and filter by FORCED_END_DATETIME\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "            df = df.dropna(subset=['datetime'])\n",
    "            df = df[df['datetime'] <= FORCED_END_DATETIME]\n",
    "\n",
    "            # Optional: print max datetime to confirm\n",
    "            print(\"Latest datetime in filtered data:\", df['datetime'].max())\n",
    "\n",
    "            # Extract date\n",
    "            df['date'] = df['datetime'].dt.date\n",
    "\n",
    "            # Determine all possible dates and missing dates\n",
    "            all_dates = pd.date_range(df['date'].min(), FORCED_END_DATETIME.date(), freq='D').date\n",
    "            existing_dates = df['date'].unique()\n",
    "            missing_dates = [date for date in all_dates if date not in existing_dates]\n",
    "\n",
    "            # Initialize\n",
    "            zero_data_dates = []\n",
    "            data_presence = []\n",
    "            filtered_df = pd.DataFrame()  # Will hold only non-zero rows\n",
    "\n",
    "            for date in existing_dates:\n",
    "                day_data = df[df['date'] == date]\n",
    "\n",
    "                # Check if ALL rows for the day are zero\n",
    "                if (day_data[['pm25', 'pm10', 'aqi', 'co2', 'voc', 'temp', 'humidity', 'battery', 'viral_index']] == 0).all().all():\n",
    "                    zero_data_dates.append(date)\n",
    "                else:\n",
    "                    # Exclude rows where all monitored values are zero\n",
    "                    valid_day_data = day_data[\n",
    "                        ~(day_data[['pm25', 'pm10', 'aqi', 'co2', 'voc', 'temp', 'humidity', 'battery', 'viral_index']] == 0).all(axis=1)\n",
    "                    ]\n",
    "                    presence_percentage = (len(valid_day_data) / 1440) * 100\n",
    "                    data_presence.append({'Date': date, 'Data Presence (%)': presence_percentage})\n",
    "\n",
    "                    # Add to filtered_df for quality calculation\n",
    "                    filtered_df = pd.concat([filtered_df, valid_day_data])\n",
    "\n",
    "            # Data quality calculation\n",
    "            if not filtered_df.empty:\n",
    "                start_datetime = filtered_df['datetime'].min()\n",
    "\n",
    "                if start_datetime > FORCED_END_DATETIME:\n",
    "                    expected_records = 0\n",
    "                    actual_records = 0\n",
    "                    overall_data_quality = 0\n",
    "                    end_datetime = start_datetime\n",
    "                else:\n",
    "                    end_datetime = FORCED_END_DATETIME\n",
    "                    total_minutes = int((end_datetime - start_datetime).total_seconds() / 60) + 1\n",
    "                    expected_records = total_minutes\n",
    "                    actual_records = len(filtered_df)\n",
    "                    overall_data_quality = (actual_records / expected_records) * 100\n",
    "            else:\n",
    "                start_datetime = None\n",
    "                end_datetime = FORCED_END_DATETIME\n",
    "                expected_records = 0\n",
    "                actual_records = 0\n",
    "                overall_data_quality = 0\n",
    "\n",
    "            # Prepare output data\n",
    "            df1 = pd.DataFrame(missing_dates, columns=['Missing Dates'])\n",
    "            df2 = pd.DataFrame(zero_data_dates, columns=['Zero Values'])\n",
    "            df3 = pd.DataFrame(data_presence)\n",
    "            quality_df = pd.DataFrame({\n",
    "                'Metric': ['Device ID', 'Start Datetime', 'End Datetime', 'Expected Records', 'Actual Records', 'Data Quality (%)'],\n",
    "                'Value': [id_to_fetch, start_datetime, end_datetime, expected_records, actual_records, overall_data_quality]\n",
    "            })\n",
    "\n",
    "            # Combine all into one Excel sheet (aligned on index)\n",
    "            combined_df = pd.concat([df1, df2, df3, quality_df], axis=1)\n",
    "\n",
    "            # Save to Excel\n",
    "            file_path = os.path.join(save_dir, f\"{id_to_fetch}.xlsx\")\n",
    "            combined_df.to_excel(file_path, index=False)\n",
    "            print(f\"Data for Device ID {id_to_fetch} saved to {file_path}\")\n",
    "        else:\n",
    "            print(f\"No data found for Device ID: {id_to_fetch}\")\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Error while connecting to the database or fetching data:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"\\nConnection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc21860b-5fc0-4d5b-9a7c-7b984cdd679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful.\n",
      "\n",
      "Processing Device ID: 1201240075\n",
      "Data for Device ID 1201240075 saved to C:\\Users\\abhis\\Data_Validation_01-08\\1201240075.xlsx\n",
      "\n",
      "Processing Device ID: 1201240085\n",
      "Data for Device ID 1201240085 saved to C:\\Users\\abhis\\Data_Validation_01-08\\1201240085.xlsx\n",
      "\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Database credentials\n",
    "host = \"139.59.34.149\"\n",
    "user = \"neemdb\"\n",
    "password = \"(#&pxJ&p7JvhA7<B\"\n",
    "database = \"cabh_iaq_db\"\n",
    "\n",
    "# List of all device IDs you want to process\n",
    "# device_ids = [\n",
    "#     1202240026, 1202240025, 1203240081, 1202240011, 1202240027, 1203240076,\n",
    "#     1203240078, 1203240075, 1201240077, 1201240072, 1203240079, 1201240079,\n",
    "#     1201240085, 1203240083, 1203240073, 1203240074, 1201240076, 1212230160,\n",
    "#     1202240009, 1202240008, 1201240073, 1203240080, 1201240074, 1203240077,\n",
    "#     1203240082, 1202240029, 1202240028, 1202240010, 1202240012\n",
    "# ]\n",
    "\n",
    "device_ids = [\n",
    "    1201240075,1201240085\n",
    "\n",
    "]\n",
    "\n",
    "# Directory to save Excel files\n",
    "save_dir = r\"C:\\Users\\abhis\\Data_Validation_01-08\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Connect to the database\n",
    "conn = None\n",
    "try:\n",
    "    conn = mysql.connector.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "    print(\"Database connection successful.\")\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # SQL query\n",
    "    query = \"\"\"\n",
    "    SELECT id, deviceID, datetime, pm25, pm10, aqi, co2, voc, temp, humidity, battery, viral_index\n",
    "    FROM reading_db\n",
    "    WHERE deviceID = %s;\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop over each ID\n",
    "    for id_to_fetch in device_ids:\n",
    "        print(f\"\\nProcessing Device ID: {id_to_fetch}\")\n",
    "        cursor.execute(query, (id_to_fetch,))\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows, columns=[\n",
    "                \"id\", \"deviceID\", \"datetime\", \"pm25\", \"pm10\", \"aqi\", \"co2\",\n",
    "                \"voc\", \"temp\", \"humidity\", \"battery\", \"viral_index\"\n",
    "            ])\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "            df = df.dropna(subset=['datetime'])\n",
    "            df['date'] = df['datetime'].dt.date\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"No valid datetime entries for Device ID: {id_to_fetch}\")\n",
    "                continue\n",
    "\n",
    "            # Missing Dates\n",
    "            all_dates = pd.date_range(df['date'].min(), df['date'].max(), freq='D').date\n",
    "            existing_dates = df['date'].unique()\n",
    "            missing_dates = [date for date in all_dates if date not in existing_dates]\n",
    "            df1 = pd.DataFrame(missing_dates, columns=['Missing Dates'])\n",
    "            if df1.empty:\n",
    "                df1 = pd.DataFrame({'Missing Dates': ['None']})\n",
    "\n",
    "            # Zero Value Dates\n",
    "            zero_data_dates = []\n",
    "            for date in df['date'].unique():\n",
    "                day_data = df[df['date'] == date]\n",
    "                if (day_data[['pm25', 'pm10', 'aqi', 'co2', 'voc', 'temp', 'humidity', 'battery', 'viral_index']] == 0).all().all():\n",
    "                    zero_data_dates.append(date)\n",
    "            df2 = pd.DataFrame(zero_data_dates, columns=['Zero Values'])\n",
    "            if df2.empty:\n",
    "                df2 = pd.DataFrame({'Zero Values': ['None']})\n",
    "\n",
    "            # Daily Data Presence\n",
    "            data_presence = []\n",
    "            for date in df['date'].unique():\n",
    "                day_data = df[df['date'] == date]\n",
    "                presence_percentage = (len(day_data) / 1440) * 100\n",
    "                data_presence.append({'Date': date, 'Data Presence (%)': presence_percentage})\n",
    "            df3 = pd.DataFrame(data_presence)\n",
    "            if df3.empty:\n",
    "                df3 = pd.DataFrame({'Date': ['None'], 'Data Presence (%)': [0]})\n",
    "\n",
    "            # Overall Data Quality\n",
    "            start_datetime = df['datetime'].min()\n",
    "            end_datetime = df['datetime'].max()\n",
    "            total_minutes = int((end_datetime - start_datetime).total_seconds() / 60) + 1\n",
    "            expected_records = total_minutes\n",
    "            actual_records = len(df)\n",
    "            overall_data_quality = (actual_records / expected_records) * 100\n",
    "\n",
    "            quality_df = pd.DataFrame({\n",
    "                'Metric': ['Device ID', 'Start Datetime', 'End Datetime', 'Expected Records', 'Actual Records', 'Data Quality (%)'],\n",
    "                'Value': [id_to_fetch, start_datetime, end_datetime, expected_records, actual_records, overall_data_quality]\n",
    "            })\n",
    "\n",
    "            # Save to Excel\n",
    "            file_path = os.path.join(save_dir, f\"{id_to_fetch}.xlsx\")\n",
    "            with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "                df1.to_excel(writer, sheet_name='Missing Dates', index=False)\n",
    "                df2.to_excel(writer, sheet_name='Zero Values', index=False)\n",
    "                df3.to_excel(writer, sheet_name='Daily Presence (%)', index=False)\n",
    "                quality_df.to_excel(writer, sheet_name='Overall Quality', index=False)\n",
    "\n",
    "            print(f\"Data for Device ID {id_to_fetch} saved to {file_path}\")\n",
    "        else:\n",
    "            print(f\"No data found for Device ID: {id_to_fetch}\")\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Error while connecting to the database or fetching data:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"\\nConnection closed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c277e71-4698-43de-8729-f33b5cd79bff",
   "metadata": {},
   "source": [
    "### for caclulating the data percentage from the first available data points in april 2024 months and first available data point in march 2025 month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f18f4b4d-7400-43e6-8dcb-d616b07444e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful.\n",
      "\n",
      "Processing Device ID: 1202240026\n",
      "\n",
      "Processing Device ID: 1202240025\n",
      "\n",
      "Processing Device ID: 1203240081\n",
      "\n",
      "Processing Device ID: 1202240011\n",
      "\n",
      "Processing Device ID: 1202240027\n",
      "\n",
      "Processing Device ID: 1203240076\n",
      "\n",
      "Processing Device ID: 1203240078\n",
      "\n",
      "Processing Device ID: 1203240075\n",
      "\n",
      "Processing Device ID: 1201240077\n",
      "\n",
      "Processing Device ID: 1201240072\n",
      "\n",
      "Processing Device ID: 1203240079\n",
      "\n",
      "Processing Device ID: 1201240079\n",
      "\n",
      "Processing Device ID: 1201240085\n",
      "\n",
      "Processing Device ID: 1203240083\n",
      "\n",
      "Processing Device ID: 1203240073\n",
      "\n",
      "Processing Device ID: 1203240074\n",
      "\n",
      "Processing Device ID: 1201240076\n",
      "\n",
      "Processing Device ID: 1212230160\n",
      "\n",
      "Processing Device ID: 1202240009\n",
      "\n",
      "Processing Device ID: 1202240008\n",
      "\n",
      "Processing Device ID: 1201240073\n",
      "\n",
      "Processing Device ID: 1203240080\n",
      "\n",
      "Processing Device ID: 1201240074\n",
      "\n",
      "Processing Device ID: 1203240077\n",
      "\n",
      "Processing Device ID: 1203240082\n",
      "\n",
      "Processing Device ID: 1202240029\n",
      "\n",
      "Processing Device ID: 1202240028\n",
      "\n",
      "Processing Device ID: 1202240010\n",
      "\n",
      "Processing Device ID: 1202240012\n",
      "\n",
      "Processing Device ID: 1201240075\n",
      "\n",
      "Processing Device ID: 1201240078\n",
      "\n",
      "Processing Device ID: 1203240072\n",
      "No data found for Device ID: 1203240072\n",
      "\n",
      "Combined data quality saved to: C:\\Users\\abhis\\Data_Vaidation_April_March\\All_Device_Data_Quality.csv\n",
      "\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Database credentials\n",
    "host = \"139.59.34.149\"\n",
    "user = \"neemdb\"\n",
    "password = \"(#&pxJ&p7JvhA7<B\"\n",
    "database = \"cabh_iaq_db\"\n",
    "\n",
    "# Device IDs\n",
    "device_ids = [\n",
    "    1202240026, 1202240025, 1203240081, 1202240011, 1202240027, 1203240076,\n",
    "    1203240078, 1203240075, 1201240077, 1201240072, 1203240079, 1201240079,\n",
    "    1201240085, 1203240083, 1203240073, 1203240074, 1201240076, 1212230160,\n",
    "    1202240009, 1202240008, 1201240073, 1203240080, 1201240074, 1203240077,\n",
    "    1203240082, 1202240029, 1202240028, 1202240010, 1202240012, 1201240075,\n",
    "    1201240078, 1203240072\n",
    "]\n",
    "\n",
    "# Save directory and output file\n",
    "save_dir = r\"C:\\Users\\abhis\\Data_Vaidation_April_March\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "output_csv_path = os.path.join(save_dir, \"All_Device_Data_Quality.csv\")\n",
    "\n",
    "# April 1, 2024 to March 31, 2025\n",
    "filter_start = datetime(2024, 4, 1)\n",
    "filter_end = datetime(2025, 3, 31, 23, 59, 59)\n",
    "\n",
    "# List to store data for all devices\n",
    "all_device_results = []\n",
    "\n",
    "# Connect and process\n",
    "conn = None\n",
    "try:\n",
    "    conn = mysql.connector.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "    print(\"Database connection successful.\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Query with date range\n",
    "    query = \"\"\"\n",
    "    SELECT id, deviceID, datetime, pm25, pm10, aqi, co2, voc, temp, humidity, battery, viral_index\n",
    "    FROM reading_db\n",
    "    WHERE deviceID = %s AND datetime BETWEEN %s AND %s;\n",
    "    \"\"\"\n",
    "\n",
    "    for id_to_fetch in device_ids:\n",
    "        print(f\"\\nProcessing Device ID: {id_to_fetch}\")\n",
    "        cursor.execute(query, (id_to_fetch, filter_start, filter_end))\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows, columns=[\n",
    "                \"id\", \"deviceID\", \"datetime\", \"pm25\", \"pm10\", \"aqi\", \"co2\", \"voc\",\n",
    "                \"temp\", \"humidity\", \"battery\", \"viral_index\"\n",
    "            ])\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "            df = df.dropna(subset=['datetime'])\n",
    "\n",
    "            actual_start = df['datetime'].min()\n",
    "            actual_end = df['datetime'].max()\n",
    "            df = df[(df['datetime'] >= actual_start) & (df['datetime'] <= actual_end)]\n",
    "\n",
    "            total_minutes = int((actual_end - actual_start).total_seconds() / 60) + 1\n",
    "            expected_records = total_minutes\n",
    "            actual_records = len(df)\n",
    "            overall_data_quality = (actual_records / expected_records) * 100\n",
    "\n",
    "            all_device_results.append({\n",
    "                'Device ID': id_to_fetch,\n",
    "                'Start Datetime': actual_start,\n",
    "                'End Datetime': actual_end,\n",
    "                'Expected Records': expected_records,\n",
    "                'Actual Records': actual_records,\n",
    "                'Data Quality (%)': round(overall_data_quality, 2)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"No data found for Device ID: {id_to_fetch}\")\n",
    "\n",
    "    # Save all results to a single CSV file\n",
    "    final_df = pd.DataFrame(all_device_results)\n",
    "    final_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"\\nCombined data quality saved to: {output_csv_path}\")\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Error while connecting to the database or fetching data:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"\\nConnection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d6b3a-2f35-4e92-b992-f3fbd034ca7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae97a13-df6a-4c56-be00-61fe0ebae99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e084d-0e84-4a08-abad-18df20367e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376079e7-dd3f-400f-8caf-bb0b0c7e547f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530a8cd-43fa-4ba8-abee-2861cd514491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67789c2c-bc5a-4bf6-b51f-649970161878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91dbca9-408e-4f56-967b-8b9dceca1474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2181465-6cb2-4731-a212-a2280f4bdb94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1db2b502-01ea-4bcb-ad90-a6510c81e0fc",
   "metadata": {},
   "source": [
    "### For Calculating the data percentage for overall time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1efa17-1fa8-4919-917e-51b861fcf676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful.\n",
      "\n",
      "Processing Device ID: 1201240075\n",
      "\n",
      "Processing Device ID: 1201240085\n",
      "\n",
      "Overall data quality saved to: C:\\Users\\abhis\\Data_Validation_01-08\\device_data_quality.csv\n",
      "\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Database credentials\n",
    "host = \"139.59.34.149\"\n",
    "user = \"neemdb\"\n",
    "password = \"(#&pxJ&p7JvhA7<B\"\n",
    "database = \"cabh_iaq_db\"\n",
    "\n",
    "# List of all device IDs to process\n",
    "device_ids = [1201240075, 1201240085]\n",
    "\n",
    "# Directory to save the CSV file\n",
    "save_dir = r\"C:\\Users\\abhis\\Data_Validation_01-08\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Output list to collect all device data quality\n",
    "output_data = []\n",
    "\n",
    "# Connect to the database\n",
    "conn = None\n",
    "try:\n",
    "    conn = mysql.connector.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "    print(\"Database connection successful.\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # SQL query\n",
    "    query = \"\"\"\n",
    "    SELECT datetime\n",
    "    FROM reading_db\n",
    "    WHERE deviceID = %s;\n",
    "    \"\"\"\n",
    "\n",
    "    for device_id in device_ids:\n",
    "        print(f\"\\nProcessing Device ID: {device_id}\")\n",
    "        cursor.execute(query, (device_id,))\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows, columns=[\"datetime\"])\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "            df = df.dropna(subset=['datetime'])\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"No valid datetime entries for Device ID: {device_id}\")\n",
    "                continue\n",
    "\n",
    "            start_datetime = df['datetime'].min()\n",
    "            end_datetime = df['datetime'].max()\n",
    "            total_minutes = int((end_datetime - start_datetime).total_seconds() / 60) + 1\n",
    "            expected_records = total_minutes\n",
    "            actual_records = len(df)\n",
    "            overall_data_quality = (actual_records / expected_records) * 100\n",
    "\n",
    "            output_data.append({\n",
    "                'Device ID': device_id,\n",
    "                'Start Datetime': start_datetime,\n",
    "                'End Datetime': end_datetime,\n",
    "                'Expected Records': expected_records,\n",
    "                'Actual Records': actual_records,\n",
    "                'Data Quality (%)': round(overall_data_quality, 2)\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            print(f\"No data found for Device ID: {device_id}\")\n",
    "\n",
    "    # Save all device results into a single CSV\n",
    "    output_df = pd.DataFrame(output_data)\n",
    "    output_csv_path = os.path.join(save_dir, \"device_data_quality.csv\")\n",
    "    output_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"\\nOverall data quality saved to: {output_csv_path}\")\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Error while connecting to the database or fetching data:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"\\nConnection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7e23c-da56-49cc-95c5-45cbf062f133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
